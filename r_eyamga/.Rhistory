source("utils_template.R")
load("./markdown.RData")
## specify the packages needed
pkgs <- c("bookdown","DT", "leaflet", "splines2", "webshot", "bigrquery","plotly","scales","RColorBrewer","data.table","tidyverse","knitr","corrplot",
"cluster", "Rtsne", "FactoMineR", "factoextra", 'fpc', 'NbClust', 'rjson',
"Hmisc","stats", "janitor", "lubridate", "testthat", "magrittr", "bookdown",
"purrr", "healthcareai", "RSQLite", "comorbidity", "DataExplorer", "skimr", "summarytools",
"explore", "dataMaid", "explor", "slickR", "htmlwidgets", "kableExtra")
need.packages(pkgs)
source("./library_load.R")
library(cluster)
library(Rtsne)
library(cowplot)
library(svglite)
library(FactoMineR)
library(factoextra)
library(fpc)
library(NbClust)
source("./library_load.R")
library(cluster)
library(Rtsne)
library(cowplot)
library(svglite)
library(FactoMineR)
library(factoextra)
library(fpc)
library(NbClust)
coda19 <- read_csv("./imputedset/covid24h_precluster.csv")
coda19 <- read_csv("./imputedset/covid24h_precluster.csv")
setwd("/data8/projets/Mila_covid19/code/eyamga/phenotyper/code/r_eyamga")
# Loading imputed dataset
# Original dataset
# setwd("/data8/projets/Mila_covid19/code/eyamga/phenotyper/code/r_eyamga")
coda19 <- read_csv("./imputedset/covid24h_precluster.csv")
# Method 1 blindly using means only
coda19 <- coda19%>%select(-contains("min"))
coda19 <- coda19%>%select(-contains("max"))
coda19index <- caret::createDataPartition(coda19$death, p=0.75, list = FALSE, times=1)
coda19 <- coda19[coda19index,]
coda19test<- coda19[-coda19index,]
# Removing a few duplicated patients
coda19 <- coda19%>%distinct(patient_site_uid, .keep_all = TRUE)
coda19 <- coda19%>%select(-patient_site_uid) # Removing ID from the clustering algorithm
# Converting the appropriate datatypes into categorical and numerical
coda19 <- coda19%>%mutate_if(function(x){(length(unique(x)) <= 13)}, function(x){as.factor(x)})
coda19 <- coda19%>%mutate_if(function(x){(length(unique(x)) >= 13)}, function(x){as.numeric(x)})
coda19 <- read_csv("./imputedset/covid24h_precluster.csv")
# Loading imputed dataset
# Original dataset
# setwd("/data8/projets/Mila_covid19/code/eyamga/phenotyper/code/r_eyamga")
coda19 <- read_csv("./data/imputed/covid24h_imputed.csv")
# Method 1 blindly using means only
coda19 <- coda19%>%select(-contains("min"))
coda19 <- coda19%>%select(-contains("max"))
coda19index <- caret::createDataPartition(coda19$death, p=0.75, list = FALSE, times=1)
coda19 <- coda19[coda19index,]
coda19test<- coda19[-coda19index,]
# Removing a few duplicated patients
coda19 <- coda19%>%distinct(patient_site_uid, .keep_all = TRUE)
coda19 <- coda19%>%select(-patient_site_uid) # Removing ID from the clustering algorithm
# Converting the appropriate datatypes into categorical and numerical
coda19 <- coda19%>%mutate_if(function(x){(length(unique(x)) <= 13)}, function(x){as.factor(x)})
coda19 <- coda19%>%mutate_if(function(x){(length(unique(x)) >= 13)}, function(x){as.numeric(x)})
# See column types
coltypes <- str(coda19)
sapply(coda19, class) #alternatively typeof
# FAMD analysis - pre clustering, simply looking at variance of the mixed dataset
res.coda19 <- FAMD(coda19,
sup.var = c(1,220), #DEATH is not included for now
graph = FALSE,
ncp=25)
## Inspect principal components
kable(get_eigenvalue(res.coda19))%>%
kable_styling(bootstrap_options = c("striped", "hover"))
fviz_famd_ind(res.coda19,
col.ind = "#2eb135",
label = "none",
repel = TRUE) +
xlim(-5, 5) + ylim (-4.5, 4.5)
get_famd_ind(res.coda19)
# Compute Gower Distances
gower_distance <- cluster::daisy(coda19, metric = "gower")
gower_mat <- as.matrix(coda19_gower)
# Print most similar patients
demo <- coda19[which(gower_mat == min(gower_mat[gower_mat != min(gower_mat)]), arr.ind = TRUE)[1, ], ]
# Print most dissimilar clients
demo2 <- coda19[which(gower_mat == max(gower_mat[gower_mat != max(gower_mat)]), arr.ind = TRUE)[1, ], ]
# K-means clustering
# Main advantage of the eclust function, is that multiple clustering algorithms can be run
# Can specify distance measure but only for continuous variables
km.res <- eclust(coda19, "kmeans", k = 3, nstart = 25, stand=TRUE, graph = FALSE)
# Visualize k-means clusters
fviz_cluster(km.res, geom = "point", ellipse.type = "norm",
palette = "jco", ggtheme = theme_minimal())
#  Evaluating optimal Number of clusters - this plot will not work as the dataset is not standardized
fviz_nbclust(coda19, FUNcluster = kmeans, method = "wss", stand=TRUE)
# Trying different values of k from 2 to 8
tsne_obj <- Rtsne(gower_distance, is_distance = TRUE)
plotslist = list()
for(i in 2:8){
pam_fit <- pam(gower_distance, diss = TRUE, k = i)
pam_results <- coda19 %>%
mutate(cluster = pam_fit$clustering) %>%
group_by(cluster) %>%
do(the_summary = summary(.))
tsne_data <- tsne_obj$Y %>%
data.frame() %>%
setNames(c("X", "Y")) %>%
mutate(cluster = factor(pam_fit$clustering))
p <- ggplot(aes(x = X, y = Y,), data = tsne_data) +
geom_point(aes(color = cluster))+
ggtitle(paste0(as.character(i), " K-means clustering"))
plotslist[[i]] <- p
}
options(repr.plot.width = 20, repr.plot.height = 20)
p <- plot_grid(plotlist = plotslist, ncol = 3)
ggsave2("k-meanscluster.svg", plot =p, width=20,height=20, limitsize = FALSE)
silhouette <- c()
silhouette = c(silhouette, NA) for (i in 2:10){
pam_clusters = pam(as.matrix(gower_distance),
diss = TRUE,
k = i)
silhouette = c(silhouette ,pam_clusters$silinfo$avg.width)
}
plot(1:10, silhouette,
xlab = "Clusters",
ylab = "Silhouette Width")
lines(1:10, silhouette)
fviz_silhouette(pam_fit, palette = "jco", ggtheme = theme_classic())
# Silhouette details bad observations
silinfo <- pam_fit$silinfo
# Average cluster silinfo$clus.avg.widths
head(pam_fit$silinfo$widths)
# Seeing bad observations
sil <- pam_fit$silinfo$widths
neg_sil_index <- which(sil[, 'sil_width'] < 0)
sil[neg_sil_index, , drop = FALSE]
res.hc <- hclust(d = coda19_gower, method = "ward.D2") #Step Two - Linkage (Ward minimizes Within Cluster Variance)
fviz_dend(res.hc, cex = 0.6, k = 3, rect = TRUE)
fviz_dend(res.hc, cex = 0.6, k = 4, type = "circular", rect = TRUE)
# Validation of the algorithm
# If cophrenetic Distance preserves pairwise distances between original and unmodeled data
# Acceptable if > 0.75
res.coph <- cophenetic(res.hc)
cor(coda19_gower, res.coph)
# Final clustering algorithm ----------------------------------------------
# Final k value =3
k=3
pam_fit <- pam(coda19_gower, diss = TRUE, k)
pam_results <- coda19 %>%
mutate(cluster = pam_fit$clustering) %>%
group_by(cluster) %>%
do(the_summary = summary(.))
# Results - Variables per cluster
# This is also done later through EDA
print(pam_results$the_summary)
tsne_obj <- Rtsne(coda19_gower, is_distance = TRUE)
tsne_data <- tsne_obj$Y %>%
data.frame() %>%
setNames(c("X", "Y")) %>%
mutate(cluster = factor(pam_fit$clustering))
# Plotting the clustering results on TSNE
p <- ggplot(aes(x = X, y = Y,), data = tsne_data) +
geom_point(aes(color = cluster))+
ggtitle("3 K-means clustering")
show(p)
# Plotting the clustering results on PCA
# Difficult to interpret as data not scaled in this iteration and categorical data
pam_fit$data <- coda19
fviz_cluster(pam_fit, geom = "point", ellipse.type = "norm")
# Plotting the results on FAMD
library(FactoMineR, quietly=T)
library(factoextra, quietly=T)
library(plotly, quietly=T)
# Must return indices
# https://nextjournal.com/pc-methods/hierarchical-clustering-pcs
# https://cran.r-project.org/web/packages/invctr/vignettes/insiders.html
coda19 <- coda19%>%mutate_if(function(x){(length(unique(x)) <= 13)}, function(x){as.factor(x)})
# By using FAMD plot above , trying reinjecting clusters results and color by cluster  # OR applying the FAMD algorithm on the clustered dataset with cluster variables already present
coda19$cluster <- pam_fit$clustering
res.coda19.cluster <- FAMD(coda19,
sup.var = c(136), #Cluster
graph = FALSE,
ncp=25)
fviz_famd_ind(res.coda19.cluster,
col.ind = "#2eb135",
label = "none",
repel = TRUE) +
xlim(-5, 5) + ylim (-4.5, 4.5)
# Adding clusters back to the original dataset
coda19$cluster <- pam_fit$clustering
# Looking at trends for different clusters
library(autoEDA)
autoEDA_results <- autoEDA(coda19,
y = "cluster", returnPlotList = TRUE,
outcomeType = "automatic", removeConstant = TRUE,
removeZeroSpread = TRUE, removeMajorityMissing = TRUE,
imputeMissing = TRUE, clipOutliers = FALSE,
minLevelPercentage = 0.025, predictivePower = TRUE,
outlierMethod = "tukey", lowPercentile = 0.01,
upPercentile = 0.99, plotCategorical = "groupedBar",
plotContinuous = "histogram", bins = 30,
rotateLabels = TRUE, color = "#26A69A",
verbose = FALSE)
## Plot figures in a grid
p <- plot_grid(plotlist = autoEDA_results$plots, ncol = 3)
show(p)
ggsave("cluster_analysis.svg", width=20,height=84, limitsize = FALSE)
##  Most important features for our k Clustering
res <- autoEDA_results$overview[autoEDA_results$overview$PredictivePower %in% c("High", "Medium"),]
res[, c('Feature', 'PredictivePowerPercentage', 'PredictivePower')]
## Exploring TSNE Data
tsne_data %>%
filter(X > 15 & X < 25,
Y > -15 & Y < -10) %>%
left_join(college_clean, by = "name") %>%
collect %>%
.[["name"]]
